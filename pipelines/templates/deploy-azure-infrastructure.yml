#
# Template that builds the Azure infrastructure for the data pipeline and project.
#

parameters:
  - name: serviceConnection
    displayName: 'Azure Resource Manager service connection'
    type: string

  - name: resourceGroupName
    displayName: 'Azure Resource Group Name'
    type: string

  - name: projectGroupName
    displayName: 'Project User Group Name'
    type: string

  - name: dataServicePrincipalClientId
    displayName: 'Data Pipeline Service Principal Client ID'
    type: string

  - name: storageAccountName
    displayName: 'ADLS Storage Account Name'
    type: string

  - name: pipelineContainerName
    displayName: 'ADLS Gen 2 Filesystem Container for the Pipeline Data'
    type: string

  - name: projectContainerName
    displayName: 'ADLS Gen 2 Filesystem Container for the Project Data'
    type: string

  - name: keyVaultName
    displayName: 'Azure Key Vault Name'
    type: string

  - name: dataFactoryName
    displayName: 'Azure Data Factory Name'
    type: string

  - name: armTemplatesLocation
    displayName: 'Location of ARM templates'
    type: string

  - name: scriptsLocation
    displayName: 'Location of Scripts'
    type: string


steps:
  # Get the Azure Location of the Resource Group
  - task: AzureCLI@2
    displayName: 'Get the Azure Location of ${{ parameters.resourceGroupName }}'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      scriptLocation: 'inlineScript'
      inlineScript: |
        rg_location=$(az group show --name "${{ parameters.resourceGroupName }}" --query location)
        [ -n "${rg_location}" ] && echo "##vso[task.setvariable variable=resourceGroupLocation;issecret=false]${rg_location}" || exit 1

  # Deploy the Azure Data Lake Gen 2 Storage Account
  - task: AzureResourceManagerTemplateDeployment@3
    displayName: 'Deploy Data Lake Storage Gen2 Account'
    inputs:
      deploymentScope: 'Resource Group'
      azureResourceManagerConnection: ${{ parameters.serviceConnection }}
      action: 'Create Or Update Resource Group'
      resourceGroupName: ${{ parameters.resourceGroupName }}
      location: $(resourceGroupLocation)
      templateLocation: 'Linked artifact'
      csmFile: '${{ parameters.armTemplatesLocation }}/azure-data-lake-gen-2.json'
      overrideParameters: '-storageAccountName ${{ parameters.storageAccountName }}'
      deploymentMode: 'Incremental'
      deploymentName: ${{ parameters.storageAccountName }}
      deploymentOutputs: 'armOutput'

  # Extract the Storage Account Resource ID from ARM output
  - task: AzurePowerShell@5
    displayName: 'Extract Storage Account ID from ARM output'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      ScriptPath: '${{ parameters.scriptsLocation }}/get_arm_output.ps1'
      ScriptArguments: "'$(armOutput)' storageAccountId"
      azurePowerShellVersion: 'LatestVersion'

  # Assign the "Storage Blob Data Contributor" Role on the Storage Account to the data pipeline Service Principal
  - task: AzureCLI@2
    displayName: 'Assign "Storage Blob Data Contributor" on Storage Account to the data pipeline Service Principal'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      scriptPath: '${{ parameters.scriptsLocation }}/add_role_assignment.sh'
      arguments: '"Storage Blob Data Contributor" "${{ parameters.dataServicePrincipalClientId }}" "$(storageAccountId)"'

  # Assign the "Storage Blob Data Reader" Role on the Storage Account to the Project group
  - task: AzureCLI@2
    displayName: 'Assign "Storage Blob Data Reader" on Storage Account to the Project group'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      scriptPath: '${{ parameters.scriptsLocation }}/add_role_assignment.sh'
      arguments: '"Storage Blob Data Reader" "${{ parameters.projectGroupName }}" "$(storageAccountId)"'

  # Create the Pipeline Filesystem Container in the Azure Data Lake Storage Gen2 account
  - task: AzureCLI@2
    displayName: 'Create Pipeline Container in the Storage Account'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      scriptPath: '${{ parameters.scriptsLocation }}/create_adls_filesystem.sh'
      arguments: '"${{ parameters.storageAccountName }}" "${{ parameters.pipelineContainerName }}"'

  # Create the Project Filesystem Container in the Azure Data Lake Storage Gen2 account
  - task: AzureCLI@2
    displayName: 'Create Project Container in the Storage Account'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      scriptPath: '${{ parameters.scriptsLocation }}/create_adls_filesystem.sh'
      arguments: '"${{ parameters.storageAccountName }}" "${{ parameters.projectContainerName }}"'

  # Get the Azure Key Vault URL
  - task: AzureCLI@2
    displayName: 'Get the Azure Location of ${{ parameters.resourceGroupName }}'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      scriptLocation: 'inlineScript'
      inlineScript: |
        vault_url=$(az keyvault show --resource-group "${{ parameters.resourceGroupName }}" --name ${{ parameters.keyVaultName }} --query properties.vaultUri                                                                       )
        [ -n "${vault_url}" ] && echo "##vso[task.setvariable variable=keyVaultUrl;issecret=false]${vault_url}" || exit 1

  # Get the ObjectId of the Azure Pipelines Service Endpoint Principal
  - task: AzureCLI@2
    displayName: 'Get the ObjectId of Azure Pipelines Principal'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      scriptPath: '${{ parameters.scriptsLocation }}/get_object_details.sh'

  # Add the Azure Pipelines Service Endpoint Principal to the Key Vault Access policies with 'list get set' permissions on secrets
  - task: AzureCLI@2
    displayName: 'Add data pipeline Service Principal to Key Vault policies'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      ScriptPath: '${{ parameters.scriptsLocation }}/add_key_vault_policy.sh'
      arguments: '"${{ parameters.keyVaultName }}" "$(objectId)" "list get set"'

  # Add the data pipeline Service Principal to the Key Vault Access policies with 'list get set' permissions on secrets
  - task: AzureCLI@2
    displayName: 'Add data pipeline Service Principal to Key Vault policies'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      ScriptPath: '${{ parameters.scriptsLocation }}/add_key_vault_policy.sh'
      arguments: '"${{ parameters.keyVaultName }}" "${{ parameters.dataServicePrincipalClientId }}" "list get set"'

  # Deploy the Azure Data Factory with a Key Vault linked service
  - task: AzureResourceManagerTemplateDeployment@3
    displayName: 'Deploy Azure Data Factory'
    inputs:
      deploymentScope: 'Resource Group'
      azureResourceManagerConnection: ${{ parameters.serviceConnection }}
      action: 'Create Or Update Resource Group'
      resourceGroupName: ${{ parameters.resourceGroupName }}
      location: $(resourceGroupLocation)
      templateLocation: 'Linked artifact'
      csmFile: '${{ parameters.armTemplatesLocation }}/azure-data-factory-with-key-vault.json'
      overrideParameters: '-factoryName ${{ parameters.dataFactoryName }} -keyVaultName ${{ parameters.keyVaultName }} -keyVaultUrl $(keyVaultUrl)'
      deploymentMode: 'Incremental'
      deploymentName: ${{ parameters.dataFactoryName }}
      deploymentOutputs: 'armOutput'

  # Extract the Azure Data Factory System Identity from the previous ARM output
  - task: AzurePowerShell@5
    displayName: 'Extract ADF System Identity from ARM output'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      ScriptPath: '${{ parameters.scriptsLocation }}/get_arm_output.ps1'
      ScriptArguments: "'$(armOutput)' dataFactorySystemIdentity"
      azurePowerShellVersion: 'LatestVersion'

  # Extract the Azure Data Factory Resource ID from the previous ARM output
  - task: AzurePowerShell@5
    displayName: 'Extract ADF Resource ID from ARM output'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      ScriptPath: '${{ parameters.scriptsLocation }}/get_arm_output.ps1'
      ScriptArguments: "'$(armOutput)' dataFactoryId"
      azurePowerShellVersion: 'LatestVersion'

  # Add the Azure Data Factory System Identity to the Key Vault Access policies with 'list get' permissions on secrets
  - task: AzureCLI@2
    displayName: 'Add ADF Identity to Key Vault policies'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      ScriptPath: '${{ parameters.scriptsLocation }}/add_key_vault_policy.sh'
      arguments: '"${{ parameters.keyVaultName }}" "$(dataFactorySystemIdentity)" "list get"'

  # Assign the "Reader" Role on the Resource Group to the data pipeline Service Principal
  - task: AzureCLI@2
    displayName: 'Assign "Reader" on Resource Group to the data pipeline Service Principal'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      ScriptPath: '${{ parameters.scriptsLocation }}/add_role_assignment.sh'
      arguments: '"Reader" "${{ parameters.dataServicePrincipalClientId }}" "${{ parameters.resourceGroupName }}"'

  # Assign the "Reader" Role on the Resource Group to the Project group
  - task: AzureCLI@2
    displayName: 'Assign "Reader" on Resource Group to the Project group'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      ScriptPath: '${{ parameters.scriptsLocation }}/add_role_assignment.sh'
      arguments: '"Reader" "${{ parameters.projectGroupName }}" "${{ parameters.resourceGroupName }}"'

  # Assign the "Data Factory Contributor" Role on the Resource Group to the data pipeline Service Principal
  - task: AzureCLI@2
    displayName: 'Assign "Data Factory Contributor" on Resource Group to the data pipeline Service Principal'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      ScriptPath: '${{ parameters.scriptsLocation }}/add_role_assignment.sh'
      arguments: '"Data Factory Contributor" "${{ parameters.dataServicePrincipalClientId }}" "${{ parameters.resourceGroupName }}"'

  # Assign the "Data Factory Contributor" Role on the Resource Group to the Project group
  - task: AzureCLI@2
    displayName: 'Assign "Data Factory Contributor" on Resource Group to the Project group'
    inputs:
      azureSubscription: ${{ parameters.serviceConnection }}
      scriptType: 'bash'
      ScriptPath: '${{ parameters.scriptsLocation }}/add_role_assignment.sh'
      arguments: '"Data Factory Contributor" "${{ parameters.projectGroupName }}" "${{ parameters.resourceGroupName }}"'
